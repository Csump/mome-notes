# 7. óra: Mesterséges intelligencia és kreativitás

## Kérdéskészlet

1. Attól függ.
2. Igen.
3. Nem, sőt. // (Lehet, hogy de? – Gyakornokprobléma!)
4. Igen.
5. Nem.
6. Nem.

## Intelligencia

Mire jó?

* Információszerzés
* Infóértelmezés
* Összefüggések találása
* Tudás elraktározása
* Alkalmas helyzetben tudás előszedése

Általános infók

* Többszintű, többkomponensű
  * Emberi (IQ, EQ, RQ: racionális gondolkodás) / állati
* Eredetileg mozgáskoordináció miatt jött létre
  * A többi evolúciós melléktermék
  * Folyamat végén: önreflexió, stratégia stb.
* Modellt alkot a külvilágról
* Állati érzékszervek > növényi (változóbb környezet)
  * Genetikailag kódolt + tanult
* Emberi: fejlettebb (komplex társadalom, nem csak közvetlen információk, hanem pld. mások által érzékelt információk, belső állapotuk meghatározása)
  * Korlátozott erőforrás (memória stb.) -> tömörített információ! -> a modellünk alapján fontosnak vélt infók tárolása, fölösleg kuka
  * Fölöslegszűrés minősége ++ => intelligencia ++
  * Sosem lesz tökéletes a való világ modellezése!
* Adaptáció
  * Vizuális kéreg alján idegsejtek -> éldetektálás (vízszintes, függőleges) -> városi környezetben több, természetben élőknél kevesebb
* Optikai illúziók: nem hibákra mutatnak rá, hanem az optimális agyműködésre
  * Aktuálisan érzékelt infók + meglévő tudás kombinálása
* Technológiai szingularitás
  * Intelligenciarobbanás -> biológiai korlátoktól mentes intelligencia -> önmagát szabadon fejleszti -> véges idő alatt bármekkora számítási kapacitás (fizikai korlátokon belül)
  * Exponenciális kapacitásnövekedés
  * Moore törvény
  * *Kurzweil: A szingularitás küszöbén*

MI

* Gyenge MI
  * Adott funkcióra fejlesztett
* Erős MI
  * AGI (Artificial General Intelligence)
  * Általános célú, ez velet a technológiai szingularitáshoz
* Gépi tanulás
  * Deep Blue -> sakkprogram (világbajnok megverése)
    * 1997.
    * 6-12 lépést értékelt ki előre
    * Ez még nem gépi tanulásos
  * Alpha Go -> go-ra fejlesztett játszóprogram (világbajnok megverése)
    * 2015., 2016.
    * Ez már gépi tanulásos
  * Játék jó terep: a végén bináris visszajelzést tudsz adni (nyertél-e)
  * Modellt tanulja a gép (statisztikai tanulás)
* Neuronhálózatok
  * ~szinapszisok erőssége ~ súlyozott élek a neuronok között
  * a kapcsolat meghatározóbb, mint maguk a neuronok
  * tanulás során belső súlyok változtatgatása
  * bármilyen bonyolult függvényt bármilyen precizitással meg tud közelíteni egy elég bonyolult neur. hálózat
* Deep Learning (mélytanulás)
  * minták alapján tanul
  * neuronhálózatok tanítóalgoritmusa: backpropagation algoritmus
    * ennek az elmélete már a '60-as években is létezett
  * deep learning: rétegekbe szervezett, nagy neuronhálók

MI forradalom okai

* **adatbőség**: rengeteg adat halmozódott fel, ezeknek meg rengeteg adat kell
* **megnövekedett számítógépes kapacitás**: elérhető árú GPU-k (konkurens algoritmusok -> párhuzamos folyamatok) -> GPU farmok
  * 30-40x-es sebességnövekedés
* **algoritmusfejlődés**: mély neurális hálók, attention mechanizmus stb.
* **hatékony nyelvi kommunikáció**: nagy nyelvi modellek, hétköznapi nyelvek használata (promptíráskor nem kódolni kell) stb.

Gépi tanulás

* fajtái
  * felügyelt tanulás (supervised learning)
    * adott egy címkézett adat, meg kell tanulnunk, hogy mi micsoda
    * adatpárok vannak
    * létezik egy elvárt függvény, amit meg kell tanulni
    * példákat adunk, mindig tudunk visszajelzést adni
    * pld. önvezető autók, kézírás felismerése, orvosi diagnosztikai algoritmusok stb.
  * felügyelet nélküli tanulás
    * klaszterezés, kategorizáció
    * csak adat van, abban kell önállóan mintákat felismerni
    * ebben még nem annyira fejlett az MI
    * önálló fogalomkategróiák, pld. élő-élettelen stb.
    * ez tömörítésre is jó
  * megerősítéses tanulás
    * akciók sorozatát követeli meg
    * döntések, cselekvések után kap visszajelzést a folyamat végén
    * pld. játékok (sakk végén tudod meg, hogy nyertél-e, de a lépéseidtől függ)
* tanulás módja
  * backpropagation
    * hátulról kezdve megnézzük, hogy ahhoz, hogy jó eredményt kapjon, hogyan kell változtatni a súlyozást
    * elég minta után kialakul a függvény
    * feketedoboz: nem tudjuk, hogy mi alapján működik (pld. képfelismerésnél nem ismert, hogy milyen szabály alapján végzi el a kiértékelést)
      * ~intuíció
    * *Geoffrey Hinton interjúk!*
  * input layer -> hidden layer(s) -> output

Idegrendszer

* valószínűségi alapú működés
* pontatlan érzékszervek
  * szem: 3D -> 2D -> 3D-s rekonstrukció
  * információvesztés, bizonytalanságok, veszteségek pótlása, becslése
* Ha egy szövegben csak az első és utolsó betű stimmel, a többit összekeverjük, attól még olvasható marad a szöveg
  * generált képekkel is ez a helyzet -> automatikus agyi javítás

Generatív modell

* sztochasztikus
  * prompt -> valami
  * input -> új tartalom (kép, zene stb.) generálása
  * nincs elvárás
* GAN (Generative Adversarial Networks)
  * 2 neurális hálózat párbajozik egymással, visszajeleznek egymásnak
  * egyik: generátorhálózat
    * valósnak tűnő képeket generál
  * másik: discriminator
    * vegyesen kap hamis és valóságos képeket, ezeket különbözteti meg
    * visszajelzést ad a generátorhálózatnak, ami alapján ő módosítja a súlyait
  * instabil, időigényes folyamat
* diffúziós modellek
  * diffúzió: zaj lépésenkénti hozzáadása (zajmentes kép -> ... -> zaj)
  * inverz diffúzió kell nekünk -> zajból kép
  * cél: zaj eltüntetése a képről
  * zajtalanítás / konvergencia
  * agyban is: pixelek -> élek -> objektumok -> teljes kép
  * pld. Stable Diffusion
    * publikus, ingyenesen elérhető adatbázisostul (LAION-5B)
    * erős GPU kell hozzá
  * LAION-5B
    * 6 mrd (kép, alt szöveg) pár
    * V1 legnagyobb szabadon hozzáférhető adatbázis
* ControlNET:
  * edge-to-image (építészet, térképek, vázlatok kidolgozása)
  * depth-to-image (depth map -> ~szürkeárnyalatos kép)
  * edge-to-pose (emberi kép vagy sziluett pozícióját ülteti át más képen lévő karakterbe)
  * saját modellek: optimális: 8-15 kép alapján (stílustanítás)
    * minél egyformább a háttér, látószög stb., annál hatékonyabb
    * azonos képkivágást érdemes használni

Kreativitás

* „A kreativitás annyit tesz, hogy készen vagyunk a tévedésre.” – Ken Robinson
* korábban elszigetelt tapasztalatok közötti kapcsolatok találása
* képgenerátor: néha túl sablonos, néha túl asszociatív -> nincs még hozzájuk csatolva egy felülbíráló mechanizmus (de dolgoznak rajta)
  * agyban is: intuitív + racionális gonodlkodás is jelen van

Veszély: gyakornoki rendszer

* MI a középszerű munkákat ki tudja váltani, olcsóbb
* de így nem lesz senior utánpótlás, ha nem vesznek fel kezdőket, gyakornokokat (hiszen az MI jobb náluk)
  * nem tud kifejlődni egy következő senioradag

Kitekintés, közeljövő

* adattisztaság kérdése
  * nincsenek címkék, hogy ez szemét, vagy sem
* hitelesség, megbízhatóság
  * pld. chatGPT-nek nincs enciklopédikus tudása
  * megoldások: belső mechanizmusok lekövetése (fekete doboz megismerése) vagy külső megerősítés, hitelesítés
* személyre szabott MI
  * erőforrásigényes
  * kutatások folynak
* társadalmak, demokráciák, befolyásolás
  * leggyorsabban terjedő technológia
  * MI cégeknél hatalmas információs hatalom + potenciális befolyásolási lehetőség van
    * lehet nagyon jól, és nagyon rosszul is használni
  * ha már hiteles lesz, milliókat lehet vele befolyásolni
* kvantumszámítógépek + neuroinformatika
  * segíti a betanulás személyre szabhatóságát (qbit >>> bit)
  * kvantumszámítógépek hatékonyabbak

Fogalmi háló

* szavak tokenizálása: szám hozzárendelése
* egymáshoz közeli szavak egymáshoz közeli számot kapnak
  * ha ki lehet cserélni két szót a legtöbb esetben a mondatokban úgy, hogy az értelmes marad, akkor közel vannak
  * ha sehol sem lehet kicserélni, távol marad
  * (+ köztes állapotok)
